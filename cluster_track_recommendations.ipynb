{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json file\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = json.load(open('playlists.json', 'r'))\n",
    "tracks = json.load(open('track_features.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'title', 'danceability', 'energy', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature']\n"
     ]
    }
   ],
   "source": [
    "playlists_df = pd.read_csv('playlists.csv')\n",
    "playlists_df = playlists_df.drop(['key'], axis=1)\n",
    "\n",
    "# Train test split\n",
    "np.random.seed(42)\n",
    "msk = np.random.rand(len(playlists_df)) < 0.8\n",
    "playlists_df, test_playlists_df = playlists_df[msk], playlists_df[~msk]\n",
    "\n",
    "headers = playlists_df.columns.values.tolist()\n",
    "\n",
    "print(headers)\n",
    "\n",
    "mean = playlists_df[headers[2:]].mean(axis=0)\n",
    "std = playlists_df[headers[2:]].std(axis=0)\n",
    "\n",
    "playlists_df[headers[2:]] = (playlists_df[headers[2:]] - mean) / std\n",
    "test_playlists_df[headers[2:]] = (test_playlists_df[headers[2:]] - mean) / std\n",
    "\n",
    "cluster_headers = headers[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlists_df = pd.read_csv('playlists_embeddings.csv')\n",
    "# cols = ['danceability', 'energy', 'loudness', 'mode', 'speechiness',\n",
    "#         'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "#         'duration_ms', 'time_signature']\n",
    "# playlists_df = playlists_df.drop(cols + ['key'], axis=1)\n",
    "\n",
    "# # Train test split\n",
    "# np.random.seed(42)\n",
    "# msk = np.random.rand(len(playlists_df)) < 0.8\n",
    "# playlists_df, test_playlists_df = playlists_df[msk], playlists_df[~msk]\n",
    "\n",
    "# headers = playlists_df.columns.values.tolist()\n",
    "\n",
    "# print(headers)\n",
    "\n",
    "# mean = playlists_df[headers[2:]].mean(axis=0)\n",
    "# std = playlists_df[headers[2:]].std(axis=0)\n",
    "\n",
    "# playlists_df[headers[2:]] = (playlists_df[headers[2:]] - mean) / std\n",
    "# test_playlists_df[headers[2:]] = (test_playlists_df[headers[2:]] - mean) / std\n",
    "\n",
    "# cluster_headers = headers[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_tracks(playlists_df, cluster_preds, num_clusters, verbose=False):\n",
    "    global playlists, tracks\n",
    "    \n",
    "    playlists_clustered = playlists_df.get(['index', 'title']).copy()\n",
    "    playlists_clustered['cluster'] = cluster_preds\n",
    "\n",
    "    cluster_tracks = [{} for _ in range(num_clusters)]\n",
    "    for cluster in range(num_clusters):\n",
    "        for i in playlists_clustered[playlists_clustered['cluster'] == cluster]['index']:\n",
    "            for track in playlists[i][1]:\n",
    "                if track['track_uri'] not in cluster_tracks[cluster]:\n",
    "                    cluster_tracks[cluster][track['track_uri']] = track\n",
    "        cluster_tracks[cluster] = np.array(list(cluster_tracks[cluster].values()))\n",
    "\n",
    "        if verbose:\n",
    "            print('Cluster {}: {} tracks'.format(cluster, len(cluster_tracks[cluster])))\n",
    "\n",
    "    return cluster_tracks\n",
    "\n",
    "def cluster_custom_score(playlists_df, cluster_preds, num_clusters):\n",
    "    global tracks\n",
    "    \n",
    "    cluster_tracks = get_cluster_tracks(playlists_df, cluster_preds, num_clusters)\n",
    "\n",
    "    lengths = np.array([len(tracks) for tracks in cluster_tracks])\n",
    "\n",
    "    return np.sum(lengths) / len(tracks), \\\n",
    "        np.max(lengths) / len(tracks), \\\n",
    "        np.std(lengths) / np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 15\n",
    "kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=42, n_init='auto').fit(playlists_df[headers[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group playlists by cluster\n",
    "playlists_df['cluster'] = kmeans.labels_\n",
    "playlists_clustered = playlists_df.get(['index', 'title', 'cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('chill', 213), ('summer', 121), ('music', 83), ('good', 83), ('2017', 82), ('2016', 78), ('jams', 76), ('new', 70), ('songs', 64), ('playlist', 59)]\n",
      "[('christmas', 188), ('disney', 101), ('chill', 70), ('songs', 44), ('music', 43), ('the', 42), ('oldies', 34), ('sleep', 29), ('feels', 29), ('musicals', 23)]\n",
      "[('rap', 133), ('hop', 79), ('hip', 73), ('old', 59), ('school', 46), ('workout', 23), ('eminem', 22), ('the', 20), ('good', 19), ('throwback', 18)]\n",
      "[('chill', 40), ('jazz', 16), ('house', 15), ('good', 12), ('2016', 11), ('music', 10), ('the', 10), ('2015', 10), ('electronic', 9), ('study', 8)]\n",
      "[('classical', 57), ('music', 30), ('study', 29), ('instrumental', 19), ('piano', 16), ('sleep', 16), ('jazz', 13), ('the', 9), ('christmas', 9), ('of', 8)]\n",
      "[('rock', 166), ('workout', 113), ('edm', 69), ('music', 52), ('playlist', 41), ('my', 39), ('metal', 39), ('new', 31), ('songs', 31), ('gym', 29)]\n",
      "[('country', 754), ('rock', 142), ('summer', 131), ('songs', 76), ('music', 75), ('playlist', 74), ('good', 71), ('jams', 66), ('the', 56), ('new', 56)]\n",
      "[('chill', 157), ('songs', 86), ('love', 67), ('music', 66), ('the', 65), ('feels', 54), ('good', 53), ('worship', 50), ('new', 44), ('sad', 43)]\n",
      "[('sleep', 1)]\n",
      "[('party', 149), ('summer', 111), ('dance', 104), ('music', 90), ('throwback', 90), ('workout', 85), ('jams', 71), ('playlist', 71), ('songs', 68), ('good', 64)]\n",
      "[('banda', 20), ('corridos', 18), ('mexicano', 4), ('spanish', 3), ('ariel', 3), ('camacho', 3), ('â¤ï¸', 3), ('ðŸ‡²ðŸ‡½', 3), ('music', 3), ('julion', 2)]\n",
      "[('worship', 106), ('gospel', 26), ('music', 26), ('jesus', 26), ('christian', 19), ('praise', 17), ('songs', 12), ('rock', 7), ('jams', 7), ('playlist', 7)]\n",
      "[('oldies', 153), ('old', 88), ('country', 72), ('rock', 72), ('classic', 64), ('music', 48), ('the', 47), ('classics', 47), ('christmas', 47), ('good', 45)]\n",
      "[('sleep', 2), ('study', 1), ('sad', 1), ('songs', 1), ('meditation', 1), ('nature', 1), ('sounds:', 1), ('orchestra', 1), ('free', 1), ('white', 1)]\n",
      "[('rap', 181), ('lit', 109), ('party', 87), ('workout', 68), ('music', 66), ('new', 61), ('hype', 57), ('chill', 50), ('up', 47), ('playlist', 42)]\n"
     ]
    }
   ],
   "source": [
    "# Count most common titles\n",
    "def count_words(titles):\n",
    "    words = []\n",
    "    for title in titles:\n",
    "        title = str(title).strip().lower()\n",
    "        words += title.split(\" \")\n",
    "    return Counter(words)\n",
    "\n",
    "\n",
    "for i in range(NUM_CLUSTERS):\n",
    "    print(count_words(\n",
    "        playlists_clustered[playlists_clustered['cluster'] == i]['title'].values.tolist()).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('chill', 56), ('summer', 30), ('2017', 27), ('new', 26), ('vibes', 22), ('good', 19), ('songs', 18), ('2016', 17), ('playlist', 15), ('music', 15)]\n",
      "[('christmas', 53), ('chill', 24), ('disney', 20), ('songs', 14), ('music', 11), ('sleep', 10), ('sad', 8), ('2017', 7), ('slow', 7), ('oldies', 6)]\n",
      "[('rap', 26), ('hop', 12), ('old', 12), ('hip', 11), ('school', 9), ('party', 7), ('throwback', 6), ('chill', 5), ('gym', 5), ('workout', 5)]\n",
      "[('chill', 8), ('house', 4), ('jazz', 4), ('2016', 4), ('playlist', 3), ('2017', 3), ('electronic', 3), ('summer', 3), ('2015', 3), ('music', 3)]\n",
      "[('study', 14), ('music', 11), ('classical', 10), ('instrumental', 6), ('sleep', 5), ('piano', 5), ('time', 4), ('the', 4), ('movie', 3), ('soundtracks', 3)]\n",
      "[('workout', 34), ('rock', 32), ('edm', 24), ('music', 13), ('mix', 12), ('songs', 12), ('punk', 8), ('up', 7), ('gym', 7), ('playlist', 7)]\n",
      "[('country', 182), ('rock', 37), ('summer', 31), ('good', 19), ('new', 17), ('music', 16), ('the', 16), ('playlist', 13), ('songs', 13), ('jams', 13)]\n",
      "[('chill', 38), ('songs', 20), ('love', 18), ('music', 13), ('country', 13), ('feels', 11), ('the', 11), ('sad', 11), ('2016', 11), ('playlist', 10)]\n",
      "[]\n",
      "[('party', 35), ('summer', 30), ('dance', 27), ('workout', 24), ('songs', 21), ('music', 19), ('throwback', 18), ('work', 18), ('throwbacks', 17), ('jams', 16)]\n",
      "[('corridos', 8), ('banda', 6), ('playlist', 2), ('waltz', 2), ('sierreÃ±o', 1), ('paisa', 1), ('ðŸ‘ŒðŸ‘ŒðŸ‘Œ', 1), ('canciones', 1), ('alma', 1), ('spanish', 1)]\n",
      "[('worship', 25), ('jesus', 7), ('christian', 7), ('music', 7), ('gospel', 7), ('church', 5), ('songs', 5), ('jams', 3), ('me', 2), ('playlist', 2)]\n",
      "[('oldies', 36), ('country', 20), ('rock', 18), ('classics', 18), ('old', 17), ('the', 15), ('good', 15), ('classic', 14), ('wedding', 13), ('playlist', 11)]\n",
      "[('orchestral', 1)]\n",
      "[('rap', 53), ('lit', 29), ('party', 24), ('workout', 20), ('playlist', 16), ('music', 15), ('summer', 14), ('up', 14), ('jams', 13), ('2017', 12)]\n"
     ]
    }
   ],
   "source": [
    "test_playlists_df['cluster'] = kmeans.predict(test_playlists_df[headers[2:]])\n",
    "test_playlists_clustered = test_playlists_df.get(['index', 'title', 'cluster'])\n",
    "\n",
    "for i in range(NUM_CLUSTERS):\n",
    "    print(count_words(\n",
    "        test_playlists_clustered[test_playlists_clustered['cluster'] == i]['title'].values.tolist()).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get recommendations (for test playlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nn is always based on Spotify features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'title', 'danceability', 'energy', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14']\n"
     ]
    }
   ],
   "source": [
    "playlists_clusters = playlists_df['cluster'].copy()\n",
    "test_playlists_clusters = test_playlists_df['cluster'].copy()\n",
    "\n",
    "playlists_df = pd.read_csv('playlists.csv')\n",
    "playlists_df = playlists_df.drop(['key'], axis=1)\n",
    "cols = ['danceability', 'energy', 'loudness', 'mode', 'speechiness',\n",
    "        'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "        'duration_ms', 'time_signature']\n",
    "playlists_df, test_playlists_df = playlists_df[msk], playlists_df[~msk]\n",
    "\n",
    "headers = playlists_df.columns.values.tolist()\n",
    "\n",
    "print(headers)\n",
    "\n",
    "mean = playlists_df[headers[2:]].mean(axis=0)\n",
    "std = playlists_df[headers[2:]].std(axis=0)\n",
    "\n",
    "playlists_df[headers[2:]] = (playlists_df[headers[2:]] - mean) / std\n",
    "test_playlists_df[headers[2:]] = (test_playlists_df[headers[2:]] - mean) / std\n",
    "\n",
    "playlists_df = pd.concat((playlists_df, playlists_clusters), axis=1)\n",
    "test_playlists_df = pd.concat((test_playlists_df, test_playlists_clusters), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = mean[:len(cols)]\n",
    "std = std[:len(cols)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge for the **input** only withholds a constant number of tracks. For simplicity, **we just withhold half the playlist.**\n",
    "\n",
    "The challenge **output** requires a **list of 500 recommended candidate tracks**, ordered by relevance in decreasing order. We omit the ordering since we do not evaluate the ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_tracks = get_cluster_tracks(playlists_df, playlists_df['cluster'], NUM_CLUSTERS)\n",
    "\n",
    "PART_PERCENT = 0.5 # Percentage of playlist to use for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_features(playlist_tracks, mean=mean, std=std):\n",
    "    features = [np.mean([track[col] for track in playlist_tracks]) for col in cols]\n",
    "    return np.array((features - mean) / std)\n",
    "\n",
    "def get_track_info(tracks):\n",
    "    return np.array([[s['artist_name'], s['track_name']] for s in tracks])\n",
    "\n",
    "def get_track_features(tracks, mean=mean, std=std, hashmap=False):\n",
    "    if hashmap:\n",
    "        features = {uri: [tracks[uri][col] for col in cols] for uri in tracks}\n",
    "        return {uri: np.array((f - mean) / std) for uri, f in features.items()}\n",
    "\n",
    "    features = np.array([[s[col] for col in cols] for s in tracks])\n",
    "    return np.array((features - np.array(mean)) / np.array(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nn(k, needle_features, haystack_features):\n",
    "    \"\"\"\n",
    "    Given an instance of features, find the k nearest neighbors in the haystack. \n",
    "    Return indexes within haystack.\n",
    "    \"\"\"\n",
    "    distances = np.linalg.norm(needle_features - haystack_features, axis=1)\n",
    "    return np.argsort(distances)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_precision(pred_tracks: set, target_tracks: set):\n",
    "    return len(pred_tracks.intersection(target_tracks)) / len(target_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nn to find nearest playlists (then randomly sample tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_playlists_predictions(init_tracks, target_tracks, playlist_part_features, part_cluster):\n",
    "    pred_tracks = init_tracks.copy()\n",
    "    \n",
    "    haystack_playlists = playlists_df[playlists_df['cluster'] == part_cluster] \n",
    "    haystack_features = haystack_playlists[cols].values\n",
    "\n",
    "    for i in k_nn(500 + len(init_tracks), playlist_part_features, haystack_features):\n",
    "        pred_playlist = haystack_playlists.iloc[i]\n",
    "        i = pred_playlist['index']\n",
    "        \n",
    "        for uri in [track['track_uri'] for track in playlists[i][1]]:\n",
    "            pred_tracks.add(uri)\n",
    "\n",
    "            if len(pred_tracks) >= 500 + len(init_tracks):\n",
    "                break\n",
    "\n",
    "        if len(pred_tracks) >= 500 + len(init_tracks):\n",
    "            break\n",
    "\n",
    "    pred_tracks = pred_tracks - init_tracks\n",
    "\n",
    "    return r_precision(pred_tracks, target_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-NN to find tracks nearest to playlist aggregate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_aggregate_predictions(init_tracks, target_tracks, playlist_part_features, tracks_in_cluster, track_features):\n",
    "    pred_tracks = init_tracks.copy()\n",
    "    \n",
    "    for i in k_nn(500 + len(init_tracks), playlist_part_features, track_features):\n",
    "        pred_tracks.add(tracks_in_cluster[i]['track_uri'])\n",
    "\n",
    "        if len(pred_tracks) >= 500 + len(init_tracks):\n",
    "            break\n",
    "\n",
    "    pred_tracks = pred_tracks - init_tracks\n",
    "\n",
    "    return r_precision(pred_tracks, target_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-NN to find tracks nearest to random tracks in playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_track_predictions(init_tracks, target_tracks, playlist_part_tracks, tracks_in_cluster, track_features, all_track_features_dict):\n",
    "    pred_tracks = init_tracks.copy()\n",
    "    \n",
    "    playlist_track_features = [all_track_features_dict[track['track_uri']] for track in playlist_part_tracks]\n",
    "    playlist_track_nn = [k_nn(len(track_features), features, track_features) for features in playlist_track_features] # bottleneck\n",
    "\n",
    "    for i in range(500):\n",
    "        for track_nn in playlist_track_nn:\n",
    "            pred_tracks.add(tracks_in_cluster[track_nn[i]]['track_uri'])\n",
    "\n",
    "            if len(pred_tracks) >= 500 + len(init_tracks):\n",
    "                break\n",
    "\n",
    "        if len(pred_tracks) >= 500 + len(init_tracks):\n",
    "            break\n",
    "\n",
    "    pred_tracks = pred_tracks - init_tracks\n",
    "\n",
    "    return r_precision(pred_tracks, target_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_track_features = [get_track_features(cluster_tracks[i]) for i in range(NUM_CLUSTERS)]\n",
    "all_track_features_dict = get_track_features(tracks, hashmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.98%\n",
      "3.02%\n",
      "2.90%\n"
     ]
    }
   ],
   "source": [
    "playlists_predictions_score = 0\n",
    "aggregate_predictions_score = 0\n",
    "track_predictions_score = 0\n",
    "\n",
    "num_test = len(test_playlists_df) // 100\n",
    "\n",
    "for test_i in range(num_test):\n",
    "\n",
    "    i = test_playlists_df.iloc[test_i]['index']\n",
    "\n",
    "    playlist_name = playlists[i][0]\n",
    "    playlist_tracks = playlists[i][1]\n",
    "    np.random.shuffle(playlist_tracks)\n",
    "\n",
    "    playlist_part_tracks = playlist_tracks[:int(\n",
    "        len(playlists[i][1]) * PART_PERCENT)]\n",
    "\n",
    "    playlist_part_features = get_playlist_features(playlist_part_tracks)\n",
    "\n",
    "    playlist_features = np.array(\n",
    "        test_playlists_df.iloc[test_i][headers[2:]].values, dtype='float32')\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        part_cluster = kmeans.predict([test_playlists_df.iloc[test_i][cluster_headers]])[0]\n",
    "\n",
    "    tracks_in_cluster = cluster_tracks[part_cluster]\n",
    "    track_features = cluster_track_features[part_cluster]\n",
    "\n",
    "    init_tracks = set([track['track_uri'] for track in playlist_part_tracks])\n",
    "    target_tracks = set([track['track_uri']\n",
    "                        for track in playlist_tracks]) - init_tracks\n",
    "\n",
    "    playlists_predictions_score += nearest_playlists_predictions(\n",
    "        init_tracks, target_tracks, playlist_part_features, part_cluster)\n",
    "\n",
    "    aggregate_predictions_score += nearest_aggregate_predictions(\n",
    "        init_tracks, target_tracks, playlist_part_features, tracks_in_cluster, track_features)\n",
    "\n",
    "    track_predictions_score += nearest_track_predictions(\n",
    "        init_tracks, target_tracks, playlist_part_tracks, tracks_in_cluster, track_features, all_track_features_dict)\n",
    "    \n",
    "print(f'{100 * playlists_predictions_score / num_test:.2f}%')\n",
    "print(f'{100 * aggregate_predictions_score / num_test:.2f}%')\n",
    "print(f'{100 * track_predictions_score / num_test:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
